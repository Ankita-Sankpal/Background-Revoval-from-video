{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujtEzF_fWkzE"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install opencv-python numpy Pillow\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Download RVM model (CORRECTED)\n",
        "model = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"mobilenetv3\", pretrained=True)  # or \"resnet50\" for better quality\n",
        "model = model.eval().cuda() if torch.cuda.is_available() else model.eval()\n",
        "\n",
        "# Upload video file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Video processing function\n",
        "def process_video_rvm(input_path, output_path, background_color=(0, 0, 0)):\n",
        "    # Initialize video capture\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Initialize video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Initialize recurrent states\n",
        "    rec = [None] * 4  # RVM uses 4 recurrent states\n",
        "    downsample_ratio = 0.25  # Adjust based on video resolution\n",
        "\n",
        "    # Background tensor\n",
        "    bg = torch.tensor(background_color).view(1, 3, 1, 1).float() / 255\n",
        "    bg = bg.cuda() if torch.cuda.is_available() else bg\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert frame to tensor\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        src = ToTensor()(frame_rgb).unsqueeze(0)\n",
        "        src = src.cuda() if torch.cuda.is_available() else src\n",
        "\n",
        "        # Inference\n",
        "        with torch.no_grad():\n",
        "            fgr, pha, *rec = model(src, *rec, downsample_ratio)\n",
        "\n",
        "        # Composite with background\n",
        "        out_frame = fgr * pha + bg * (1 - pha)\n",
        "\n",
        "        # Convert to numpy array\n",
        "        out_frame = out_frame[0].permute(1, 2, 0).cpu().numpy()\n",
        "        out_frame = (out_frame * 255).astype(np.uint8)\n",
        "        out_frame = cv2.cvtColor(out_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        out.write(out_frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0:\n",
        "            print(f\"Processed frame {frame_count}\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Processing complete. Saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Process video\n",
        "output_path = 'output-final-crowd_rvm.mp4'\n",
        "process_video_rvm(video_path, output_path)\n",
        "\n",
        "# Download result\n",
        "files.download(output_path)\n",
        "\n",
        "\n"
      ]
    }
  ]
}